{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2vec in Gensim \n",
    "\n",
    "The idea behind word2vec is that we make this assumption that the meaning of the word depends on the words arround it \n",
    "\n",
    "The training algo in the `gensim package` were actually ported from the original <b>Word2vec</b> implementation by <b>Google</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and logging \n",
    "import gzip\n",
    "import gensim\n",
    "import logging \n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "we will be using the OpinRank dataset. it has the data about reviews of cars and hotels from users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file = \"reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('reviews_data.txt.gz', 'rb') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files into a list \n",
    "\n",
    "we can read the file into a list so that we can pass this into the word2vec model.\n",
    "we would also be doing some minor preprocessing using the `gensim.utils.simple_preprocess(line)` which basically does is lowercasing, tokenization etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 01:41:18,317 : INFO : reading file reviews_data.txt.gz... this may take a while\n",
      "2019-06-10 01:41:18,321 : INFO : read 0 reviews\n",
      "2019-06-10 01:41:18,432 : INFO : read 10000 reviews\n",
      "2019-06-10 01:41:18,533 : INFO : read 20000 reviews\n",
      "2019-06-10 01:41:19,123 : INFO : read 30000 reviews\n",
      "2019-06-10 01:41:19,313 : INFO : read 40000 reviews\n",
      "2019-06-10 01:41:19,432 : INFO : read 50000 reviews\n",
      "2019-06-10 01:41:19,547 : INFO : read 60000 reviews\n",
      "2019-06-10 01:41:19,650 : INFO : read 70000 reviews\n",
      "2019-06-10 01:41:19,741 : INFO : read 80000 reviews\n",
      "2019-06-10 01:41:19,836 : INFO : read 90000 reviews\n",
      "2019-06-10 01:41:19,930 : INFO : read 100000 reviews\n",
      "2019-06-10 01:41:20,040 : INFO : read 110000 reviews\n",
      "2019-06-10 01:41:20,154 : INFO : read 120000 reviews\n",
      "2019-06-10 01:41:20,268 : INFO : read 130000 reviews\n",
      "2019-06-10 01:41:20,377 : INFO : read 140000 reviews\n",
      "2019-06-10 01:41:20,474 : INFO : read 150000 reviews\n",
      "2019-06-10 01:41:20,572 : INFO : read 160000 reviews\n",
      "2019-06-10 01:41:20,666 : INFO : read 170000 reviews\n",
      "2019-06-10 01:41:20,764 : INFO : read 180000 reviews\n",
      "2019-06-10 01:41:20,872 : INFO : read 190000 reviews\n",
      "2019-06-10 01:41:20,975 : INFO : read 200000 reviews\n",
      "2019-06-10 01:41:21,072 : INFO : read 210000 reviews\n",
      "2019-06-10 01:41:21,171 : INFO : read 220000 reviews\n",
      "2019-06-10 01:41:21,260 : INFO : read 230000 reviews\n",
      "2019-06-10 01:41:21,353 : INFO : read 240000 reviews\n",
      "2019-06-10 01:41:21,448 : INFO : read 250000 reviews\n",
      "2019-06-10 01:41:21,502 : INFO : Done reading the data file\n"
     ]
    }
   ],
   "source": [
    "def read_input(input_file):\n",
    "    logging.info(\"reading file {0}... this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open(input_file, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if (i%10000==0):\n",
    "                logging.info(\"read {0} reviews\".format(i))\n",
    "                \n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "                \n",
    "# read the tokenized reviews into a list \n",
    "# each review item becomes a series of words \n",
    "# so this becomes a list of lists \n",
    "\n",
    "documents = list(read_input(data_file))\n",
    "logging.info(\"Done reading the data file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model \n",
    "\n",
    "Training the model is fairly straightforward. You pass the reviews that we read in the previous step. So, we are essentially passing on a lost of list s where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary and by vocabulary we mean set of unique words.\n",
    "Afer building vocabulary we just have to call in train function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 02:12:30,554 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-06-10 02:12:30,556 : INFO : collecting all words and their counts\n",
      "2019-06-10 02:12:30,556 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-06-10 02:12:30,558 : INFO : collected 1310 word types from a corpus of 5022 raw words and 26 sentences\n",
      "2019-06-10 02:12:30,559 : INFO : Loading a fresh vocabulary\n",
      "2019-06-10 02:12:30,561 : INFO : effective_min_count=2 retains 556 unique words (42% of original 1310, drops 754)\n",
      "2019-06-10 02:12:30,563 : INFO : effective_min_count=2 leaves 4268 word corpus (84% of original 5022, drops 754)\n",
      "2019-06-10 02:12:30,567 : INFO : deleting the raw counts dictionary of 1310 items\n",
      "2019-06-10 02:12:30,568 : INFO : sample=0.001 downsamples 62 most-common words\n",
      "2019-06-10 02:12:30,569 : INFO : downsampling leaves estimated 2791 word corpus (65.4% of prior 4268)\n",
      "2019-06-10 02:12:30,571 : INFO : estimated required memory for 556 words and 150 dimensions: 945200 bytes\n",
      "2019-06-10 02:12:30,572 : INFO : resetting layer weights\n",
      "2019-06-10 02:12:30,589 : INFO : training model with 10 workers on 556 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-06-10 02:12:30,595 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,596 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,596 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,597 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,597 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,598 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,598 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,599 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,599 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,608 : INFO : EPOCH - 1 : training on 5022 raw words (2767 effective words) took 0.0s, 213411 effective words/s\n",
      "2019-06-10 02:12:30,613 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,614 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,615 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,616 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,616 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,617 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,618 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,622 : INFO : EPOCH - 2 : training on 5022 raw words (2789 effective words) took 0.0s, 275042 effective words/s\n",
      "2019-06-10 02:12:30,627 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,628 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,629 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,630 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,631 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,632 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,632 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,633 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,638 : INFO : EPOCH - 3 : training on 5022 raw words (2804 effective words) took 0.0s, 230610 effective words/s\n",
      "2019-06-10 02:12:30,648 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,650 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,650 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,651 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,652 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,652 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,653 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,654 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,664 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,665 : INFO : EPOCH - 4 : training on 5022 raw words (2792 effective words) took 0.0s, 168740 effective words/s\n",
      "2019-06-10 02:12:30,670 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,671 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,672 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,673 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,674 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,674 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,677 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,679 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,683 : INFO : EPOCH - 5 : training on 5022 raw words (2837 effective words) took 0.0s, 182855 effective words/s\n",
      "2019-06-10 02:12:30,684 : INFO : training on a 25110 raw words (13989 effective words) took 0.1s, 147964 effective words/s\n",
      "2019-06-10 02:12:30,685 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-06-10 02:12:30,686 : INFO : training model with 10 workers on 556 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-06-10 02:12:30,692 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,694 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,695 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,696 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,696 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,697 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,698 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,699 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,703 : INFO : EPOCH - 1 : training on 5022 raw words (2809 effective words) took 0.0s, 267106 effective words/s\n",
      "2019-06-10 02:12:30,710 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,712 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,713 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,714 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 02:12:30,715 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,717 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,718 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,722 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,727 : INFO : EPOCH - 2 : training on 5022 raw words (2772 effective words) took 0.0s, 162505 effective words/s\n",
      "2019-06-10 02:12:30,732 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,733 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,734 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,735 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,735 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,736 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,737 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,737 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,739 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,741 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,741 : INFO : EPOCH - 3 : training on 5022 raw words (2789 effective words) took 0.0s, 256706 effective words/s\n",
      "2019-06-10 02:12:30,747 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,749 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,750 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,751 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,753 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,754 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,755 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,759 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,761 : INFO : EPOCH - 4 : training on 5022 raw words (2797 effective words) took 0.0s, 201158 effective words/s\n",
      "2019-06-10 02:12:30,766 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,768 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,769 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,771 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,772 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,773 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,774 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,777 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,778 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,779 : INFO : EPOCH - 5 : training on 5022 raw words (2795 effective words) took 0.0s, 192542 effective words/s\n",
      "2019-06-10 02:12:30,787 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,788 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,788 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,789 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,790 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,791 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,792 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,801 : INFO : EPOCH - 6 : training on 5022 raw words (2806 effective words) took 0.0s, 172429 effective words/s\n",
      "2019-06-10 02:12:30,809 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,812 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,813 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,816 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,816 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,817 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,818 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,819 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,825 : INFO : EPOCH - 7 : training on 5022 raw words (2788 effective words) took 0.0s, 184484 effective words/s\n",
      "2019-06-10 02:12:30,831 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,832 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,832 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,833 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,834 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,835 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,835 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,837 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,844 : INFO : EPOCH - 8 : training on 5022 raw words (2781 effective words) took 0.0s, 184874 effective words/s\n",
      "2019-06-10 02:12:30,851 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,853 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,855 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-06-10 02:12:30,857 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,858 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,859 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,860 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,874 : INFO : EPOCH - 9 : training on 5022 raw words (2753 effective words) took 0.0s, 113283 effective words/s\n",
      "2019-06-10 02:12:30,879 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-06-10 02:12:30,880 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-06-10 02:12:30,881 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 02:12:30,881 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-06-10 02:12:30,882 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-06-10 02:12:30,883 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-06-10 02:12:30,884 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-10 02:12:30,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-10 02:12:30,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-10 02:12:30,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-10 02:12:30,888 : INFO : EPOCH - 10 : training on 5022 raw words (2771 effective words) took 0.0s, 267719 effective words/s\n",
      "2019-06-10 02:12:30,889 : INFO : training on a 50220 raw words (27861 effective words) took 0.2s, 137648 effective words/s\n",
      "2019-06-10 02:12:30,889 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(27861, 50220)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
